<!DOCTYPE html>
<html lang="en">
<head>
    <title>Binh T. Nguyen</title>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="blog, accent, , Binh T. Nguyen, jekyll">
    <meta name="author" content="">
    
    
    
    <meta name="description" content="">
    <link href='https://fonts.googleapis.com/css?family=Piazzolla:400,700' rel='stylesheet' type='text/css'>
    <link rel="alternate" type="application/rss+xml" title="Binh T. Nguyen RSS" href="/feed.xml" />
    <link rel="stylesheet" href="/css/main.css">
    
</head>
<body>

    <div class="wrapper">
        <div class="navbar container">
            
            <a id="author-name" class="alignable pull-left" href="">Binh T. Nguyen</a>
            <ul id="navlist" class="alignable pull-right navbar-ul">
                
                    
                        <li class="alignable pull-left nav-list"><a href="/about.html">About</a>
                    
                    
                        &nbsp;&nbsp;|
                    
                        </li>
                
                    
                        <li class="alignable pull-left nav-list"><a href="/research.html">Research</a>
                    
                    
                        &nbsp;&nbsp;|
                    
                        </li>
                
                    
                        <li class="alignable pull-left nav-list"><a href="/teaching.html">Teaching</a>
                    
                    
                        </li>
                
            </ul>
        </div>
        <div style="clear:both"></div>
        <hr>
        
            <div class="container content">
        
        <div style="text-align: justify;"> <h1
id="m2ds-alternants---course-on-thematic-research-seminar---spring-2022">M2DS
Alternants - Course on Thematic Research Seminar - Spring 2022</h1>
<p>Instructors:</p>
<ul>
<li>Binh Nguyen (binguyen@telecom-paris.fr)</li>
<li><a href="https://akorba.github.io/">Anna Korba</a>
(anna.korba@ensae.fr)</li>
</ul>
<h2 id="practical-information">Practical Information</h2>
<ul>
<li><p><strong>Room:</strong> PC102 (somewhere in between Amphi Arago,
Carnot, Monge in the GrandCampus Polytechnique). Check also:
https://www.polytechnique.edu/mapwize/</p></li>
<li><p><strong>Time:</strong> 9h30-12h15, each Thursday from 07/04 to
30/06/2022.</p></li>
<li><p><strong>Grading:</strong> based on presentation given at the 3rd
session of each topic, final note is the average of the 4
presentations.</p></li>
<li><p>First two sessions for each topic is lecture + practical Python
(technically Jupyter) notebook for coding.</p></li>
<li><p>Interaction during classes is encouraged: it’s better for you to
think as well, so prepare for some derivations/questions of the theory,
and tinkering with the practical sessions.</p></li>
<li><p>Advice: you should start working with the assigned paper as early
as possible, because you might have related questions, and can check
with us in the second session for each of the topics.</p></li>
</ul>
<h2 id="topics">Topics</h2>
<ul>
<li><p>Topic 1 (07, 14 and 21/04): Sparsity learning with Lasso <a
href="/files/lasso1.pdf">(slides-1)</a> <a
href="/files/lasso2.pdf">(slides-2)</a></p>
<p>Reference: Bühlmann, P., &amp; Geer, S. A. van de. (2011). Statistics
for high-dimensional data: Methods, theory and applications.
Springer.</p>
<p>Papers:</p>
<ol type="1">
<li>(Adaptive Lasso) Zou, H. (2006), ‘The adaptive lasso and its oracle
properties’, Journal of the American Statistical Association 101(476),
1418–1429.</li>
<li>Meinshausen, N. (2007), ‘Relaxed lasso’, Computational Statistics
&amp; Data Analysis 52, 374–393.</li>
<li>(group lasso) Yuan, M. &amp; Lin, Y. (2006), ‘Model selection and
estimation in regression with grouped variables’, Journal of the Royal
Statistical Society: Series B 68(1), 49–67.</li>
<li>(lasso for missing data) Loh, P.-L. &amp; Wainwright, M. J. (2012),
‘High-dimensional regression with noisy and missing data: Provable
guarantees with nonconvexity’, The Annals of Statistics 40(3),
1637–1664.</li>
<li>(Debiased Lasso) Van de Geer, S., Bühlmann, P., Ritov, Y. A., &amp;
Dezeure, R. (2014). On asymptotically optimal confidence regions and
tests for high-dimensional models. The Annals of Statistics, 42(3),
1166-1202.</li>
</ol></li>
<li><p>Topic 2 (28/04, 05 and 12/05): Generative Adversarial Networks <a
href="/files/generative.pdf">(slides-1)</a></p>
<p>References:</p>
<ol type="1">
<li>Goodfellow, Ian, et al. “Generative adversarial nets.” Advances in
neural information processing systems 27 (2014).</li>
<li>Arjovsky and Bottou. “Towards Principled Methods for Training
Generative Adversarial Networks.” ICLR 2017.</li>
<li>Salimans, Tim, et al. “Improved techniques for training gans.”
NeurIPS 2016</li>
<li>Arjovsky et. al. “Wasserstein generative adversarial networks.” ICML
2017.</li>
</ol>
<p>Papers:</p>
<ol type="1">
<li>Reed, Scott, et al. “Generative adversarial text to image
synthesis.” International conference on machine learning. PMLR,
2016.</li>
<li>(Conditional GAN) Wang, Ting-Chun, et al. “High-resolution image
synthesis and semantic manipulation with conditional gans.” Proceedings
of the IEEE conference on computer vision and pattern recognition.
2018.</li>
<li>(Style GAN) Karras, Tero, et al. “A style-based generator
architecture for generative adversarial networks.” Proceedings of the
IEEE/CVF conference on computer vision and pattern recognition.
2019.</li>
<li>(DC-GAN) Radford, Alec, Luke Metz, and Soumith Chintala.
“Unsupervised representation learning with deep convolutional generative
adversarial networks.” arXiv preprint arXiv:1511.06434 (2015).</li>
<li>(InfoGAN) Chen, Xi, et al. “Infogan: Interpretable representation
learning by information maximizing generative adversarial nets.”
Advances in neural information processing systems 29 (2016).</li>
<li>(LS-GAN) Mao, Xudong, et al. “Least squares generative adversarial
networks.” Proceedings of the IEEE international conference on computer
vision. 2017.</li>
</ol></li>
<li><p>Topic 3 (19, 02/06 and 09/06): Optimal Transport with
Gromov-Wasserstein distance.</p>
<p>References:</p>
<ol type="1">
<li>Gabriel Peyré and Marco Cuturi (2019), “Computational Optimal
Transport: With Applications to Data Science”, Foundations and Trends®
in Machine Learning: Vol. 11: No. 5-6, pp 355-607.
http://dx.doi.org/10.1561/2200000073</li>
<li>Mémoli, F. (2011). Gromov–Wasserstein Distances and the Metric
Approach to Object Matching. Foundations of Computational Mathematics,
11(4), 417–487. https://doi.org/10.1007/s10208-011-9093-5</li>
</ol></li>
<li><p>Topic 4 (16, 20 and 30/06): TBD</p></li>
</ul>
 </div>
                
                    <hr />
                    <p style="text-align: center; margin-bottom: 10px">
                    <a href="" style="color: black"><small>Last update: 11/05/2022</small></a>
                    </p>
                
            </div>
    </div>
     <!-- MathJax (Latex) block -->
     <script type="text/javascript">
       window.MathJax = {
	   loader: {load: ['[tex]/color']},
	   TeX: {
	       packages: {'[+]': ['color']},
	       extensions: [
		   "AMSmath.js",
		   "AMSsymbols.js",],
	       equationNumbers: { autoNumber: "all" },
	   }
       };
     </script>
     <script type="text/javascript"
             src="/files/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
     </script>
</body>
<footer>
</footer>
